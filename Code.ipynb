{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4VALcilIb-8",
        "outputId": "242f417f-00f6-43a2-f62b-b45e20d2ecfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original image counts: {'Normal': 150, 'CC': 160, 'HCC': 150}\n",
            "Dataset split completed.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuration\n",
        "BASE_DIR = '/content/drive/MyDrive'\n",
        "DATASET_DIR = os.path.join(BASE_DIR, 'Liver_Dataset')\n",
        "SPLIT_DIR = os.path.join(BASE_DIR, 'Liver_Dataset_Split')\n",
        "SEED = 42\n",
        "\n",
        "# Count images in each class before any processing\n",
        "original_counts = {}\n",
        "for cls in os.listdir(DATASET_DIR):\n",
        "    class_path = os.path.join(DATASET_DIR, cls)\n",
        "    if os.path.isdir(class_path):\n",
        "        original_counts[cls] = len([f for f in os.listdir(class_path) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "print(f\"Original image counts: {original_counts}\")\n",
        "\n",
        "# Split dataset into train, validation, and test sets\n",
        "def split_dataset(source_dir, output_dir, split_ratios=(0.7, 0.15, 0.15)):\n",
        "    random.seed(SEED)\n",
        "    classes = os.listdir(source_dir)\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        for cls in classes:\n",
        "            os.makedirs(os.path.join(output_dir, split, cls), exist_ok=True)\n",
        "    for cls in tqdm(classes, desc=\"Splitting data\"):\n",
        "        class_path = os.path.join(source_dir, cls)\n",
        "        images = [f for f in os.listdir(class_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        random.shuffle(images)\n",
        "        total = len(images)\n",
        "        train_end = int(split_ratios[0] * total)\n",
        "        val_end = train_end + int(split_ratios[1] * total)\n",
        "        splits = {'train': images[:train_end], 'val': images[train_end:val_end], 'test': images[val_end:]}\n",
        "        for split, img_list in splits.items():\n",
        "            for img in img_list:\n",
        "                src = os.path.join(class_path, img)\n",
        "                dst = os.path.join(output_dir, split, cls, img)\n",
        "                shutil.copy2(src, dst)\n",
        "print(\"Dataset split completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3l2BAkQNOlhg",
        "outputId": "de9d7f5a-5bf6-4b26-bf22-bc87a391cac3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Resizing train/Normal: 100%|██████████| 140/140 [01:50<00:00,  1.26it/s]\n",
            "Resizing train/CC: 100%|██████████| 146/146 [01:58<00:00,  1.23it/s]\n",
            "Resizing train/HCC: 100%|██████████| 139/139 [01:51<00:00,  1.24it/s]\n",
            "Resizing val/Normal: 100%|██████████| 43/43 [00:53<00:00,  1.24s/it]\n",
            "Resizing val/CC: 100%|██████████| 42/42 [00:54<00:00,  1.30s/it]\n",
            "Resizing val/HCC: 100%|██████████| 43/43 [00:55<00:00,  1.30s/it]\n",
            "Resizing test/Normal: 100%|██████████| 41/41 [00:51<00:00,  1.26s/it]\n",
            "Resizing test/CC: 100%|██████████| 44/44 [00:51<00:00,  1.18s/it]\n",
            "Resizing test/HCC: 100%|██████████| 44/44 [00:53<00:00,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-augmentation image counts: {'train/Normal': 140, 'train/CC': 145, 'train/HCC': 139, 'val/Normal': 43, 'val/CC': 41, 'val/HCC': 43, 'test/Normal': 41, 'test/CC': 43, 'test/HCC': 44}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuration\n",
        "PREPROCESSED_DIR = '/content/drive/MyDrive/Liver_Dataset_Preprocessed'\n",
        "SPLIT_DIR = '/content/drive/MyDrive/Liver_Dataset_Split'\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "# Resize images and count pre-augmented images\n",
        "def resize_images(source_dir, target_dir, size=IMG_SIZE):\n",
        "    pre_aug_counts = {}\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        for label in os.listdir(os.path.join(source_dir, split)):\n",
        "            src_path = os.path.join(source_dir, split, label)\n",
        "            tgt_path = os.path.join(target_dir, split, label)\n",
        "            os.makedirs(tgt_path, exist_ok=True)\n",
        "            pre_aug_counts[f\"{split}/{label}\"] = len([f for f in os.listdir(src_path) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "            for img_file in tqdm(os.listdir(src_path), desc=f\"Resizing {split}/{label}\"):\n",
        "                if not img_file.endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    continue\n",
        "                try:\n",
        "                    img = Image.open(os.path.join(src_path, img_file)).convert('RGB')\n",
        "                    img = img.resize(size)\n",
        "                    img.save(os.path.join(tgt_path, img_file))\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {img_file}: {e}\")\n",
        "    print(f\"Pre-augmentation image counts: {pre_aug_counts}\")\n",
        "\n",
        "resize_images(SPLIT_DIR, PREPROCESSED_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYa2rttWOsoT",
        "outputId": "4ca474b4-0ee1-48ba-b2a9-0e34038130d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Augmenting Normal: 100%|██████████| 140/140 [08:54<00:00,  3.82s/it]\n",
            "Augmenting CC: 100%|██████████| 145/145 [09:07<00:00,  3.78s/it]\n",
            "Augmenting HCC: 100%|██████████| 139/139 [08:49<00:00,  3.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Post-augmentation image counts: {'Normal': 840, 'CC': 870, 'HCC': 834}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Configuration\n",
        "PREPROCESSED_DIR = '/content/drive/MyDrive/Liver_Dataset_Preprocessed'\n",
        "\n",
        "# Augment data and count post-augmented images\n",
        "def augment_and_save(source, target, augment_count=5):  # Increased to 5 for more data\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=40, width_shift_range=0.3, height_shift_range=0.3,\n",
        "        zoom_range=0.4, horizontal_flip=True, vertical_flip=True, brightness_range=[0.8, 1.2],\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "    post_aug_counts = {}\n",
        "    for label in os.listdir(source):\n",
        "        class_src = os.path.join(source, label)\n",
        "        class_tgt = os.path.join(target, label)\n",
        "        os.makedirs(class_tgt, exist_ok=True)\n",
        "        # Copy original images\n",
        "        for img_name in os.listdir(class_src):\n",
        "            if img_name.endswith(('.jpg', '.jpeg', '.png')):\n",
        "                shutil.copy2(os.path.join(class_src, img_name), os.path.join(class_tgt, img_name))\n",
        "        # Generate augmented images\n",
        "        for img_name in tqdm(os.listdir(class_src), desc=f\"Augmenting {label}\"):\n",
        "            if not img_name.endswith(('.jpg', '.jpeg', '.png')):\n",
        "                continue\n",
        "            try:\n",
        "                img_path = os.path.join(class_src, img_name)\n",
        "                img = Image.open(img_path).convert('RGB')\n",
        "                x = np.array(img)\n",
        "                x = x.reshape((1,) + x.shape)\n",
        "                i = 0\n",
        "                for batch in datagen.flow(x, batch_size=1):\n",
        "                    aug_img = Image.fromarray(batch[0].astype('uint8'))\n",
        "                    aug_img.save(os.path.join(class_tgt, f\"{img_name.split('.')[0]}_aug{i}.jpg\"))\n",
        "                    i += 1\n",
        "                    if i >= augment_count:\n",
        "                        break\n",
        "            except Exception as e:\n",
        "                print(f\"Error augmenting {img_name}: {e}\")\n",
        "        post_aug_counts[label] = len([f for f in os.listdir(class_tgt) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "    print(f\"Post-augmentation image counts: {post_aug_counts}\")\n",
        "\n",
        "augment_and_save(os.path.join(PREPROCESSED_DIR, 'train'), os.path.join(PREPROCESSED_DIR, 'train_full'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4jcHQe9Oxp_",
        "outputId": "e53a5c53-b56a-4e86-8765-38e6737326e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2544 images belonging to 3 classes.\n",
            "Found 127 images belonging to 3 classes.\n",
            "Found 128 images belonging to 3 classes.\n",
            "Train samples: 2544, Val samples: 127, Test samples: 128\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Configuration\n",
        "PREPROCESSED_DIR = '/content/drive/MyDrive/Liver_Dataset_Preprocessed'\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Create data generators\n",
        "def create_data_generators():\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    train_gen = train_datagen.flow_from_directory(\n",
        "        os.path.join(PREPROCESSED_DIR, 'train_full'),\n",
        "        target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=True\n",
        "    )\n",
        "    val_gen = val_test_datagen.flow_from_directory(\n",
        "        os.path.join(PREPROCESSED_DIR, 'val'),\n",
        "        target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False\n",
        "    )\n",
        "    test_gen = val_test_datagen.flow_from_directory(\n",
        "        os.path.join(PREPROCESSED_DIR, 'test'),\n",
        "        target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False\n",
        "    )\n",
        "    return train_gen, val_gen, test_gen\n",
        "\n",
        "train_gen, val_gen, test_gen = create_data_generators()\n",
        "print(f\"Train samples: {train_gen.samples}, Val samples: {val_gen.samples}, Test samples: {test_gen.samples}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_OSd1R3O09g",
        "outputId": "0bb85035-b30b-47dc-99e4-8ffc642c9e74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m74836368/74836368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8243, Validation Accuracy: 0.8425, Test Accuracy: 0.8828\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import DenseNet201  # Upgraded to DenseNet201 for better performance\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Configuration\n",
        "NUM_CLASSES = 3\n",
        "\n",
        "# Build and train initial model\n",
        "base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.6)(x)  # Increased dropout\n",
        "x = Dense(256, activation='relu')(x)  # Increased units\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.4)(x)\n",
        "output = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=10, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(factor=0.5, patience=5),\n",
        "    ModelCheckpoint('initial_model.keras', save_best_only=True)\n",
        "]\n",
        "history = model.fit(train_gen, epochs=70, validation_data=val_gen, callbacks=callbacks, verbose=0)\n",
        "train_score = model.evaluate(train_gen, verbose=0)\n",
        "val_score = model.evaluate(val_gen, verbose=0)\n",
        "test_score = model.evaluate(test_gen, verbose=0)\n",
        "print(f\"Train Accuracy: {train_score[1]:.4f}, Validation Accuracy: {val_score[1]:.4f}, Test Accuracy: {test_score[1]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9yPLqWFlO4_3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b49f2a4-862d-47d1-974f-92c3a5a3b9e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9996, Validation Accuracy: 0.9606, Test Accuracy: 0.9531\n"
          ]
        }
      ],
      "source": [
        "# Fine-tune the model\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:int(0.6 * len(base_model.layers))]:  # Adjusted to unfreeze more layers\n",
        "    layer.trainable = False\n",
        "model.compile(optimizer=Adam(learning_rate=5e-6), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "fine_tune_history = model.fit(train_gen, epochs=50, validation_data=val_gen, callbacks=callbacks, verbose=0)\n",
        "train_score_ft = model.evaluate(train_gen, verbose=0)\n",
        "val_score_ft = model.evaluate(val_gen, verbose=0)\n",
        "test_score_ft = model.evaluate(test_gen, verbose=0)\n",
        "print(f\"Train Accuracy: {train_score_ft[1]:.4f}, Validation Accuracy: {val_score_ft[1]:.4f}, Test Accuracy: {test_score_ft[1]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qHfH7IoO74X"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "# Hyperparameter tuning\n",
        "param_grid = {\n",
        "    'learning_rate': [1e-6, 5e-6, 1e-5],\n",
        "    'batch_size': [12, 16, 24],\n",
        "    'dropout_rate': [0.4, 0.5, 0.6]\n",
        "}\n",
        "best_accuracy = 0\n",
        "best_params = None\n",
        "for params in ParameterGrid(param_grid):\n",
        "    print(f\"Tuning with params: {params}\")\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "    model.compile(optimizer=Adam(learning_rate=params['learning_rate']),\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(train_gen, epochs=30, validation_data=val_gen,\n",
        "                        batch_size=params['batch_size'], callbacks=callbacks, verbose=0)\n",
        "    x = model.layers[-4].output\n",
        "    x = Dropout(params['dropout_rate'])(x)\n",
        "    x = model.layers[-2](x)\n",
        "    output = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "    model.compile(optimizer=Adam(learning_rate=params['learning_rate']),\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(train_gen, epochs=30, validation_data=val_gen,\n",
        "              batch_size=params['batch_size'], callbacks=callbacks, verbose=0)\n",
        "    val_score = model.evaluate(val_gen, verbose=0)\n",
        "    if val_score[1] > best_accuracy:\n",
        "        best_accuracy = val_score[1]\n",
        "        best_params = params\n",
        "print(f\"Best parameters: {best_params}, Best Validation Accuracy: {best_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mqbxr4xwO_-E"
      },
      "outputs": [],
      "source": [
        "# Train with best parameters and final evaluation\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_gen, epochs=100, validation_data=val_gen,\n",
        "          batch_size=best_params['batch_size'], callbacks=callbacks, verbose=0)\n",
        "x = model.layers[-4].output\n",
        "x = Dropout(best_params['dropout_rate'])(x)\n",
        "x = model.layers[-2](x)\n",
        "output = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_gen, epochs=100, validation_data=val_gen,\n",
        "          batch_size=best_params['batch_size'], callbacks=callbacks, verbose=0)\n",
        "final_train_score = model.evaluate(train_gen, verbose=0)\n",
        "final_val_score = model.evaluate(val_gen, verbose=0)\n",
        "final_test_score = model.evaluate(test_gen, verbose=0)\n",
        "print(f\"Train Accuracy: {final_train_score[1]:.4f}, Validation Accuracy: {final_val_score[1]:.4f}, Test Accuracy: {final_test_score[1]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Helper function to plot graphs\n",
        "def plot_history(initial, fine_tune):\n",
        "    # Accuracy\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(initial.history['accuracy'], label='Initial Train Acc')\n",
        "    plt.plot(initial.history['val_accuracy'], label='Initial Val Acc')\n",
        "    plt.plot(fine_tune.history['accuracy'], label='Fine-Tune Train Acc')\n",
        "    plt.plot(fine_tune.history['val_accuracy'], label='Fine-Tune Val Acc')\n",
        "    plt.title('Training & Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(initial.history['loss'], label='Initial Train Loss')\n",
        "    plt.plot(initial.history['val_loss'], label='Initial Val Loss')\n",
        "    plt.plot(fine_tune.history['loss'], label='Fine-Tune Train Loss')\n",
        "    plt.plot(fine_tune.history['val_loss'], label='Fine-Tune Val Loss')\n",
        "    plt.title('Training & Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history, fine_tune_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "Su76i8rb1B9h",
        "outputId": "d788c85f-6a9c-4469-e7a4-243b6a0fcc04"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f2dcf2d2f426>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfine_tune_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy scores\n",
        "labels = ['Train', 'Validation', 'Test']\n",
        "before = [train_score[1], val_score[1], test_score[1]]\n",
        "after = [train_score_ft[1], val_score_ft[1], test_score_ft[1]]\n",
        "\n",
        "x = np.arange(len(labels))\n",
        "width = 0.35\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(x - width/2, before, width, label='Before Fine-Tuning')\n",
        "plt.bar(x + width/2, after, width, label='After Fine-Tuning')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy Comparison')\n",
        "plt.xticks(x, labels)\n",
        "plt.ylim(0, 1.1)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L6c1ydbh1HUt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}